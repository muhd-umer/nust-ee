{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a0b501",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a4b4f",
   "metadata": {},
   "source": [
    "### Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2495d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-26T07:07:05.874526Z",
     "iopub.status.busy": "2023-12-26T07:07:05.873559Z",
     "iopub.status.idle": "2023-12-26T07:07:21.326701Z",
     "shell.execute_reply": "2023-12-26T07:07:21.324278Z"
    },
    "papermill": {
     "duration": 15.461698,
     "end_time": "2023-12-26T07:07:21.328231",
     "exception": true,
     "start_time": "2023-12-26T07:07:05.866533",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Build the neural network model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation=\"relu\", input_shape=(28 * 28,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(train_images, train_labels, epochs=5, batch_size=128, validation_split=0.2)\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "# print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e181686",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ea655",
   "metadata": {},
   "source": [
    "### ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5b967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T10:54:34.832994Z",
     "iopub.status.busy": "2023-12-17T10:54:34.832622Z",
     "iopub.status.idle": "2023-12-17T10:55:51.434053Z",
     "shell.execute_reply": "2023-12-17T10:55:51.433083Z",
     "shell.execute_reply.started": "2023-12-17T10:54:34.832964Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the MNIST dataset (download it if not already present)\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype(\"float32\") / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Build the neural network model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "# print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab443fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5410c1",
   "metadata": {},
   "source": [
    "## CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7bd0da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T10:21:35.219250Z",
     "iopub.status.busy": "2023-12-18T10:21:35.218206Z",
     "iopub.status.idle": "2023-12-18T10:21:36.067309Z",
     "shell.execute_reply": "2023-12-18T10:21:36.065997Z",
     "shell.execute_reply.started": "2023-12-18T10:21:35.219205Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def load_cifar10_data(folder):\n",
    "    all_train_images, all_train_labels = [], []\n",
    "\n",
    "    # Load training data from all batches\n",
    "    for batch_num in range(1, 6):\n",
    "        batch_filename = f\"{folder}/data_batch_{batch_num}\"\n",
    "        with open(batch_filename, \"rb\") as fo:\n",
    "            batch = pickle.load(fo, encoding=\"bytes\")\n",
    "            train_images = batch[b\"data\"]\n",
    "            train_labels = np.array(batch[b\"labels\"])\n",
    "\n",
    "            all_train_images.append(train_images)\n",
    "            all_train_labels.append(train_labels)\n",
    "\n",
    "    # Load test data\n",
    "    with open(f\"{folder}/test_batch\", \"rb\") as fo:\n",
    "        batch = pickle.load(fo, encoding=\"bytes\")\n",
    "        test_images = batch[b\"data\"]\n",
    "        test_labels = np.array(batch[b\"labels\"])\n",
    "\n",
    "    # Concatenate data from all batches\n",
    "    train_images = np.concatenate(all_train_images, axis=0)\n",
    "    train_labels = np.concatenate(all_train_labels, axis=0)\n",
    "\n",
    "    return (train_images, train_labels), (test_images, test_labels)\n",
    "\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = load_cifar10_data(\n",
    "    \"./cifar10/\"\n",
    ")\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e78e0a",
   "metadata": {},
   "source": [
    "### Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d479e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T10:38:59.253229Z",
     "iopub.status.busy": "2023-12-17T10:38:59.252891Z",
     "iopub.status.idle": "2023-12-17T10:39:49.334510Z",
     "shell.execute_reply": "2023-12-17T10:39:49.333640Z",
     "shell.execute_reply.started": "2023-12-17T10:38:59.253204Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the neural network model\n",
    "model_ann = models.Sequential()\n",
    "model_ann.add(layers.Dense(512, activation=\"relu\", input_shape=(32 * 32 * 3,)))\n",
    "model_ann.add(layers.Dropout(0.5))\n",
    "model_ann.add(layers.Dense(256, activation=\"relu\"))\n",
    "model_ann.add(layers.Dropout(0.5))\n",
    "model_ann.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model_ann.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# # Train the model\n",
    "# model_ann.fit(\n",
    "#     train_images, train_labels, epochs=5, batch_size=128, validation_split=0.2\n",
    "# )\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# test_loss_ann, test_acc_ann = model_ann.evaluate(test_images, test_labels)\n",
    "# print(f\"Test accuracy (ANN): {test_acc_ann}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97598445",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_ann, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d68c336",
   "metadata": {},
   "source": [
    "### ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc1226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T10:51:50.218327Z",
     "iopub.status.busy": "2023-12-17T10:51:50.217457Z",
     "iopub.status.idle": "2023-12-17T10:53:19.538285Z",
     "shell.execute_reply": "2023-12-17T10:53:19.537441Z",
     "shell.execute_reply.started": "2023-12-17T10:51:50.218302Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape images to (32, 32, 3)\n",
    "train_images = train_images.reshape((train_images.shape[0], 32, 32, 3))\n",
    "test_images = test_images.reshape((test_images.shape[0], 32, 32, 3))\n",
    "\n",
    "# Build the convolutional neural network model\n",
    "model_cnn = models.Sequential()\n",
    "model_cnn.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)))\n",
    "model_cnn.add(layers.MaxPooling2D((3, 3)))\n",
    "model_cnn.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model_cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "model_cnn.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model_cnn.add(layers.Flatten())\n",
    "model_cnn.add(layers.Dense(64, activation=\"relu\"))\n",
    "model_cnn.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model_cnn.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# # Train the model\n",
    "# model_cnn.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# test_loss_cnn, test_acc_cnn = model_cnn.evaluate(test_images, test_labels)\n",
    "# print(f\"Test accuracy (CNN): {test_acc_cnn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d5f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_cnn, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6c36d",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6f08f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T10:21:49.489995Z",
     "iopub.status.busy": "2023-12-18T10:21:49.489561Z",
     "iopub.status.idle": "2023-12-18T10:21:50.919308Z",
     "shell.execute_reply": "2023-12-18T10:21:50.918125Z",
     "shell.execute_reply.started": "2023-12-18T10:21:49.489949Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((train_images.shape[0], 32, 32, 3))\n",
    "test_images = test_images.reshape((test_images.shape[0], 32, 32, 3))\n",
    "# ResNet18\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Add, Activation, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def residual_block(x, filters, stride):\n",
    "    shortcut = x\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=stride,\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "    )(x)\n",
    "    x = Conv2D(filters=filters, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "    # Skip connection\n",
    "    if stride > 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(\n",
    "            filters=filters, kernel_size=(1, 1), strides=stride, padding=\"same\"\n",
    "        )(shortcut)\n",
    "    x = Add()([shortcut, x])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet18(input_shape, num_classes):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(7, 7),\n",
    "        strides=(2, 2),\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "    )(input)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    # Residual blocks\n",
    "    x = residual_block(x, filters=64, stride=1)\n",
    "    x = residual_block(x, filters=64, stride=1)\n",
    "    x = residual_block(x, filters=128, stride=2)\n",
    "    x = residual_block(x, filters=128, stride=1)\n",
    "    x = residual_block(x, filters=256, stride=2)\n",
    "    x = residual_block(x, filters=256, stride=1)\n",
    "    x = residual_block(x, filters=512, stride=2)\n",
    "    x = residual_block(x, filters=512, stride=1)\n",
    "    # Output layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=input, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "model = resnet18(input_shape, 10)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# model.fit(train_images, train_labels, epochs=1, batch_size=64, validation_split=0.2)\n",
    "# # Evaluate the model on the test set\n",
    "# test_loss_cnn, test_acc_cnn = model.evaluate(test_images, test_labels)\n",
    "# print(f'Test accuracy (CNN): {test_acc_cnn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e757aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca04fee",
   "metadata": {},
   "source": [
    "## U-Net (Autoencoder / Encoder-Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0dc235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T19:27:53.198915Z",
     "iopub.status.busy": "2023-12-18T19:27:53.197982Z",
     "iopub.status.idle": "2023-12-18T19:28:50.784780Z",
     "shell.execute_reply": "2023-12-18T19:28:50.784000Z",
     "shell.execute_reply.started": "2023-12-18T19:27:53.198877Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Signal Denoising\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, concatenate\n",
    "from keras.losses import MeanSquaredError\n",
    "\n",
    "\n",
    "def create_frames(data, frame_size, hop_size):\n",
    "    num_samples = len(data)\n",
    "    num_frames = (num_samples - frame_size) // hop_size + 1\n",
    "\n",
    "    frames = np.zeros((num_frames, frame_size), dtype=data.dtype)\n",
    "    for i in range(num_frames):\n",
    "        start = i * hop_size\n",
    "        end = start + frame_size\n",
    "        frames[i] = data[start:end]\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "# Load and preprocess audio data\n",
    "def load_and_preprocess_data(audio_path, sr=48000):\n",
    "    audio, _ = librosa.load(audio_path, sr=sr, mono=True)\n",
    "    return audio\n",
    "\n",
    "\n",
    "def wave_unet(input_shape=(None, 1)):\n",
    "    # Encoder\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv1 = Conv1D(64, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "\n",
    "    conv2 = Conv1D(128, 3, activation=\"relu\", padding=\"same\")(pool1)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "\n",
    "    conv3 = Conv1D(256, 3, activation=\"relu\", padding=\"same\")(pool2)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(conv3)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv4 = Conv1D(512, 3, activation=\"relu\", padding=\"same\")(pool3)\n",
    "\n",
    "    # Decoder\n",
    "    up5 = UpSampling1D(size=2)(conv4)\n",
    "    concat5 = concatenate([conv3, up5], axis=-1)\n",
    "    conv5 = Conv1D(256, 3, activation=\"relu\", padding=\"same\")(concat5)\n",
    "\n",
    "    up6 = UpSampling1D(size=2)(conv5)\n",
    "    concat6 = concatenate([conv2, up6], axis=-1)\n",
    "    conv6 = Conv1D(128, 3, activation=\"relu\", padding=\"same\")(concat6)\n",
    "\n",
    "    up7 = UpSampling1D(size=2)(conv6)\n",
    "    concat7 = concatenate([conv1, up7], axis=-1)\n",
    "    conv7 = Conv1D(64, 3, activation=\"relu\", padding=\"same\")(concat7)\n",
    "\n",
    "    # Output layer\n",
    "    output = Conv1D(1, 1, activation=\"linear\", padding=\"same\")(conv7)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output, name=\"wave_unet\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Load and preprocess data\n",
    "path = \"./raw.wav\"\n",
    "clean_signal = load_and_preprocess_data(path)\n",
    "clean_signal = clean_signal[:100000]\n",
    "max_abs_value = np.max(np.abs(clean_signal))\n",
    "clean_signal = clean_signal / max_abs_value\n",
    "white_noise = np.random.normal(0, 0.1, len(clean_signal))\n",
    "noisy_signal = clean_signal + white_noise\n",
    "\n",
    "# Define frame parameters\n",
    "frame_size = 1024\n",
    "hop_size = 512\n",
    "\n",
    "# Create frames\n",
    "clean_frames = create_frames(clean_signal, frame_size, hop_size)\n",
    "noisy_frames = create_frames(noisy_signal, frame_size, hop_size)\n",
    "\n",
    "clean_frames = np.expand_dims(clean_frames, axis=-1)\n",
    "noisy_frames = np.expand_dims(noisy_frames, axis=-1)\n",
    "\n",
    "# Build the model\n",
    "model = wave_unet(input_shape=(1024, 1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError())\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(noisy_frames, clean_frames, epochs=5, batch_size=4)\n",
    "# # tf.keras.utils.plot_model(model,show_shapes=True,show_layer_names=True)\n",
    "# # # Predict the denoised sequence\n",
    "# denoised_frames = model.predict(noisy_frames)\n",
    "# denoised_frames = np.squeeze(denoised_frames, axis=-1)\n",
    "# clean_frames = np.squeeze(clean_frames, axis=-1)\n",
    "# noisy_frames = np.squeeze(noisy_frames, axis=-1)\n",
    "# predicted = denoised_frames.ravel()\n",
    "# clean = clean_frames.ravel()\n",
    "# noisy = noisy_frames.ravel()\n",
    "\n",
    "\n",
    "# # # Visualize the results\n",
    "# plt.figure()\n",
    "# plt.plot(clean, label=\"Clean Signal\")\n",
    "# plt.figure()\n",
    "# plt.plot(noisy, label=\"Noisy Signal\")\n",
    "# plt.figure()\n",
    "# plt.plot(predicted, label=\"Denoised signal\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f81660",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4179967,
     "sourceId": 7221660,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4180115,
     "sourceId": 7221873,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4188081,
     "sourceId": 7232711,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.494694,
   "end_time": "2023-12-26T07:07:23.797803",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-26T07:07:02.303109",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
